{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation du module functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlops_functions import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture du fichier\n",
    "\n",
    "# Louise\n",
    "base = functions.load_data(\"/Users/lepercqlouise/stockage_macBook/Rendu_MLOPS/athlete_events.csv\")\n",
    "# Cyrielle\n",
    "base = functions.load_data(\"/Users/lepercqlouise/stockage_macBook/Rendu_MLOPS/athlete_events.csv\")\n",
    "\n",
    "#base =  pd.read_csv(\"C:/Users/Cyrie/OneDrive/Bureau/M2_DS/S1/MLOPS/Rendu_MLOPS/athlete_events.csv\")  \n",
    "#base = pd.read_csv(\"/Users/lepercqlouise/stockage_macBook/Rendu_MLOPS/athlete_events.csv\")\n",
    "#base = pd.read_csv(\"//ad.univ-lille.fr/Etudiants/Homedir3/147794/Documents/M2/Rendu_MLOPS/athlete_events.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtre sur Summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes : 222552\n"
     ]
    }
   ],
   "source": [
    "# Filtre sur la saison d'été\n",
    "base_summer = functions.filter_summer_season(base)\n",
    "\n",
    "\n",
    "#filtre sur Summer\n",
    "#base_summer = base[base['Season'] == 'Summer']\n",
    "\n",
    "#nombre de ligne de notre df base après filtre du df base summer\n",
    "#nombre_de_lignes1 = base_summer.shape[0]\n",
    "\n",
    "#affiche le nombre de lignes du df base summer 2000\n",
    "#print(\"Nombre de lignes :\", nombre_de_lignes1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs manquantes et abbérantes du df base_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valeurs manquantes pour le df base summer\n",
    "valeurs_manquantes_par_variable1 = base_summer.isnull().sum()\n",
    "\n",
    "# Affichage du résultat pour le df base summer\n",
    "print(valeurs_manquantes_par_variable1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valeur abbérentes\n",
    "# Création de la figure et des axes\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "###################AGE#####################\n",
    "# Création de la boîte à moustaches \n",
    "sns.boxplot(x=base_summer['Medal'], y=base_summer['Age'], color='#008030')\n",
    "\n",
    "# Titres et labels\n",
    "plt.title('Boîte à moustaches de la variable age selon la médaille')\n",
    "plt.xlabel('Médaille')\n",
    "plt.show()\n",
    "\n",
    "###################Height####################\n",
    "# Création de la boîte à moustaches \n",
    "sns.boxplot(x=base_summer['Medal'], y=base_summer['Height'], color='#008080')\n",
    "\n",
    "# Titres et labels\n",
    "plt.title('Boîte à moustaches de la variable taille selon la médaille')\n",
    "plt.xlabel('Médaille')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###################Weight####################\n",
    "# Création de la boîte à moustaches \n",
    "sns.boxplot(x=base_summer['Medal'], y=base_summer['Weight'], color='#008030')\n",
    "\n",
    "# Titres et labels\n",
    "plt.title('Boîte à moustaches de la variable poids selon la médaille')\n",
    "plt.xlabel('Médaille')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture des valeurs abbérantes\n",
    "# Filtre sur les enregistrements où l'âge est supérieur à 40 et inférieur à 11 ans\n",
    "base_summer_age_11_40 = base_summer[(base_summer['Age'] > 40) | (base_summer['Age'] < 11)]\n",
    "print(\"DataFrame pour l'âge entre 11 et 40 ans inclus:\")\n",
    "print(base_summer_age_11_40)\n",
    "\n",
    "# Filtre sur les enregistrements où la taille est inférieure à 145 cm et supérieure à 210 cm\n",
    "base_summer_height_145_210 = base_summer[(base_summer['Height'] > 210) | (base_summer['Height'] < 145)]\n",
    "print(\"\\nDataFrame pour la taille entre 145 et 210 cm inclus:\")\n",
    "print(base_summer_height_145_210)\n",
    "\n",
    "# Filtre sur les enregistrements où le poids est inférieur à 35 kg et supérieur à 118 kg\n",
    "base_summer_weight_35_118 = base_summer[(base_summer['Weight'] > 118) | (base_summer['Weight'] < 35)]\n",
    "print(\"\\nDataFrame pour le poids entre 35 et 118 kg inclus:\")\n",
    "print(base_summer_weight_35_118)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regroupements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voir la répartiton des variables quantitatives avant le regroupement\n",
    "###################YEAR####################\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(base_summer['Year'], bins=30, kde=True, color='#008030', stat='density', element='bars', common_norm=False)  # Utilisation du code hexadécimal pour un bleu canard foncé\n",
    "sns.kdeplot(base_summer['Year'], color='red', linewidth=2)  # Courbe KDE en rouge\n",
    "plt.title('Répartition de la variable année ')\n",
    "plt.xlabel('Année')\n",
    "plt.ylabel('Densité')\n",
    "plt.show()\n",
    "\n",
    "###################AGE#####################\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(base_summer['Age'], bins=30, kde=True, color='#008080', stat='density', element='bars', common_norm=False)  # Utilisation du code hexadécimal pour un bleu canard foncé\n",
    "sns.kdeplot(base_summer['Age'], color='red', linewidth=2)  # Courbe KDE en rouge\n",
    "plt.title('Répartition de la variable age ')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Densité')\n",
    "plt.show()\n",
    "\n",
    "###################HEIGHT#####################\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(base_summer['Height'], bins=30, kde=True, color='#008030', stat='density', element='bars', common_norm=False)  # Utilisation du code hexadécimal pour un bleu canard foncé\n",
    "sns.kdeplot(base_summer['Height'], color='red', linewidth=2)  # Courbe KDE en rouge\n",
    "plt.title('Répartition de la variable taille ')\n",
    "plt.xlabel('Taille')\n",
    "plt.ylabel('Densité')\n",
    "plt.show()\n",
    "\n",
    "###################WEIGHT#####################\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(base_summer['Weight'], bins=30, kde=True, color='#008030', stat='density', element='bars', common_norm=False)  # Utilisation du code hexadécimal pour un bleu canard foncé\n",
    "sns.kdeplot(base_summer['Weight'], color='red', linewidth=2)  # Courbe KDE en rouge\n",
    "plt.title('Répartition de la variable poids ')\n",
    "plt.xlabel('Poids')\n",
    "plt.ylabel('Densité')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des classes d'âge\n",
    "age_classes = create_age_classes(base_summer)\n",
    "print(age_classes.head(5))\n",
    "\n",
    "# Création des classes de taille\n",
    "height_classes = create_height_classes(base_summer)\n",
    "print(height_classes.head(5))\n",
    "\n",
    "# Création des classes de poids\n",
    "weight_classes = create_weight_classes(base_summer)\n",
    "print(weight_classes.head(70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher les frequences de modalites pour les variables regroupes\n",
    "###################AGE#####################\n",
    "print(\"Fréquences de modalités pour la Classe âge:\")\n",
    "print(base_summer['Classe_age'].value_counts())\n",
    "\n",
    "###################HEIGHT#####################\n",
    "print(\"\\nFréquences de modalités pour la Classe taille:\")\n",
    "print(base_summer['Classe_height'].value_counts())\n",
    "\n",
    "###################WEIGHT#####################\n",
    "print(\"\\nFréquences de modalités pour la Classe poids:\")\n",
    "print(base_summer['Classe_weight'].value_counts())\n",
    "\n",
    "\n",
    "#fonction pour afficher les fréquences en pourcentage\n",
    "def print_percentage_counts(column_name):\n",
    "    percentages = base_summer[column_name].value_counts(normalize=True) * 100\n",
    "    print(f\"Fréquences en pourcentage pour la colonne '{column_name}':\")\n",
    "    print(percentages)\n",
    "\n",
    "# Afficher les fréquences en pourcentage pour la classe d'âge\n",
    "print_percentage_counts('Classe_age')\n",
    "\n",
    "# Afficher les fréquences en pourcentage pour la classe de taille\n",
    "print(\"\\n\")\n",
    "print_percentage_counts('Classe_height')\n",
    "\n",
    "# Afficher les fréquences en pourcentage pour la classe de poids\n",
    "print(\"\\n\")\n",
    "print_percentage_counts('Classe_weight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtre les années 2000 et suppression de variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer sur l'année supérieure ou égale à 2000\n",
    "base_summer_2000 = filter_by_year(base_summer)\n",
    "print(base_summer_2000.head())\n",
    "\n",
    "\n",
    "#filtre sur l annee sup ou egal a 2000\n",
    "#base_summer_2000 = base_summer[base_summer['Year'] >= 2000]\n",
    "\n",
    "#nombre de ligne de notre df base après filtre du df base summer 2000\n",
    "#nombre_de_lignes2 = base_summer_2000.shape[0]\n",
    "\n",
    "#affiche le nombre de lignes du df base summer 2000\n",
    "#print(\"Nombre de lignes :\", nombre_de_lignes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrer sur l'année supérieure ou égale à 2000\n",
    "base_summer_2000 = filter_by_year(base_summer)\n",
    "print(\"Avant suppression des colonnes :\")\n",
    "print(base_summer_2000.head())\n",
    "\n",
    "# Supprimer les variables 'Team' et 'Season'\n",
    "columns_to_drop = ['Team', 'Season', 'Age', 'Height', 'Weight']\n",
    "base_summer_2000 = drop_columns(base_summer_2000, columns_to_drop)\n",
    "print(\"\\nAprès suppression des colonnes :\")\n",
    "print(base_summer_2000.head())\n",
    "\n",
    "\n",
    "# Supprimer les variables 'Team' et 'Season' du DataFrame base_summer_2000\n",
    "#base_summer_2000 = base_summer_2000.drop(['Team', 'Season','Age','Height','Weight'], axis=1)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame après la suppression\n",
    "#print(base_summer_2000.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs manquantes du df base_summer_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer sur l'année supérieure ou égale à 2000\n",
    "base_summer_2000 = filter_by_year(base_summer)\n",
    "print(\"Avant suppression des colonnes :\")\n",
    "print(base_summer_2000.head())\n",
    "\n",
    "# Calculer et afficher les valeurs manquantes\n",
    "display_missing_values(base_summer_2000)\n",
    "\n",
    "\n",
    "#valeurs manquantes pour le df base summer 2000\n",
    "#valeurs_manquantes_par_variable2 = base_summer_2000.isnull().sum()\n",
    "\n",
    "# Affichage du résultat pour le df base \n",
    "#print(valeurs_manquantes_par_variable2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer sur l'année supérieure ou égale à 2000\n",
    "base_summer_2000 = filter_by_year(base_summer)\n",
    "print(\"Avant suppression des colonnes :\")\n",
    "print(base_summer_2000.head())\n",
    "\n",
    "# Supprimer les valeurs manquantes pour les colonnes spécifiques\n",
    "columns_to_check = ['Classe_age', 'Classe_height', 'Classe_weight']\n",
    "base_summer_2000_net = drop_missing_values(base_summer_2000, columns_to_check)\n",
    "print(\"\\nAprès suppression des valeurs manquantes :\")\n",
    "print(base_summer_2000_net.head())\n",
    "\n",
    "\n",
    "# suppression des valeurs manquantes \n",
    "#base_summer_2000_net = base_summer_2000.dropna(subset=['Classe_age','Classe_height','Classe_weight'])\n",
    "#base_summer_2000_net.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombre de ligne de notre df base après filtre du df base summer\n",
    "nombre_de_lignes3 = base_summer_2000_net.shape[0]\n",
    "\n",
    "#affiche le nombre de lignes du df base summer 2000\n",
    "print(\"Nombre de lignes :\", nombre_de_lignes3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistiques descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistique univarié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#008030', '#008080', '#00A86B', '#4CAF50', '#7CFC00']\n",
    "\n",
    "# Statistique sur la variable sex \n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "base_summer_2000_net['Sex'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',shadow=True,startangle=15, colors = colors)\n",
    "plt.title('Répartition des sexes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistique sur la variable classe_age\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "base_summer_2000_net['Classe_age'].value_counts().plot.pie(colors = colors,autopct='%1.1f%%')\n",
    "plt.title('Répartition des âges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistique sur la variable classe_height\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "base_summer_2000_net['Classe_height'].value_counts().plot.pie(colors = colors, autopct='%1.1f%%')\n",
    "plt.title('Répartition des tailles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistique sur la variable height\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Comptez les occurrences de chaque catégorie\n",
    "total = float(len(base_summer_2000_net[\"Classe_height\"]))\n",
    "\n",
    "# Utilisez sns.countplot pour afficher le graphique à barres\n",
    "ax = sns.countplot(x=\"Classe_height\", data=base_summer_2000_net, palette='viridis')\n",
    "\n",
    "# Modifiez l'axe y pour être en pourcentage\n",
    "def percent_formatter(x, pos):\n",
    "    return f'{(x / total):.0%}'\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(percent_formatter))\n",
    "\n",
    "# Ajoutez les pourcentages au centre des barres\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2., height / 2,\n",
    "            '{:.0%}'.format(height / total), ha=\"center\")\n",
    "\n",
    "plt.title('Répartition des tailles')\n",
    "plt.xlabel(\"Classe_height\")\n",
    "plt.ylabel('Pourcentage')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistique sur la variable weight\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "base_summer_2000_net['Classe_weight'].value_counts().plot.pie(colors = colors, autopct='%1.1f%%')\n",
    "plt.title('Répartition des poids')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistique sur la variable weight\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Comptez les occurrences de chaque catégorie\n",
    "total = float(len(base_summer_2000_net[\"Classe_weight\"]))\n",
    "\n",
    "# Utilisez sns.countplot pour afficher le graphique à barres\n",
    "ax = sns.countplot(x=\"Classe_weight\", data=base_summer_2000_net, palette='viridis')\n",
    "\n",
    "# Modifiez l'axe y pour être en pourcentage\n",
    "def percent_formatter(x, pos):\n",
    "    return f'{(x / total):.0%}'\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(percent_formatter))\n",
    "\n",
    "# Ajoutez les pourcentages au centre des barres\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2., height / 2,\n",
    "            '{:.0%}'.format(height / total), ha=\"center\")\n",
    "\n",
    "plt.title('Répartition des poids')\n",
    "plt.xlabel(\"Classe_xeight\")\n",
    "plt.ylabel('Pourcentage')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistique sur la variable NOC \n",
    "\n",
    "# Créer un DataFrame pour le nombre d'individus par pays\n",
    "tableau_noc = base_summer_2000_net.groupby('NOC').size().reset_index(name='Nombre d\\'individus')\n",
    "\n",
    "# Trier le tableau par le nombre d'individus de manière décroissante\n",
    "tableau_noc_trie = tableau_noc.sort_values(by='Nombre d\\'individus', ascending=False)\n",
    "\n",
    "# Sélectionner les 16 premiers\n",
    "les_16_premiers = tableau_noc_trie.head(16)\n",
    "\n",
    "# Afficher les 16 premiers pays les plus représentés\n",
    "les_16_premiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistique bivarié"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_plot(base_summer_2000_net, x_variable, target_variable='Medal'):\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(x=x_variable, hue=target_variable, data=base_summer_2000_net, palette='viridis')\n",
    "    plt.title(f'Répartition des {target_variable} selon leurs {x_variable}')\n",
    "    plt.xlabel(x_variable)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=target_variable)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming your DataFrame is named df\n",
    "create_bar_plot(base_summer_2000_net, 'Sex')\n",
    "create_bar_plot(base_summer_2000_net, 'Classe_age')\n",
    "create_bar_plot(base_summer_2000_net, 'Classe_height')\n",
    "create_bar_plot(base_summer_2000_net, 'Classe_weight')\n",
    "create_bar_plot(base_summer_2000_net, 'NOC')\n",
    "create_bar_plot(base_summer_2000_net, 'Games')\n",
    "create_bar_plot(base_summer_2000_net, 'Sport')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrélation entre les variables - V de Cramer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionnez vos variables catégorielles\n",
    "categorical_vars = ['Name', 'Sex', 'NOC', 'Games', 'City', 'Sport',\n",
    "                    'Event', 'Medal', 'Classe_age', 'Classe_height', 'Classe_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculez le V de Cramer et affichez la matrice de corrélation\n",
    "cramer_matrix = calculate_cramer_v(base_summer_2000_net, categorical_vars)\n",
    "plot_cramer_matrix(cramer_matrix)\n",
    "\n",
    "# Créez une table de contingence pour chaque paire de variables\n",
    "#contingency_tables = {}\n",
    "#for var1 in categorical_vars:\n",
    "#   for var2 in categorical_vars:\n",
    "#        contingency_table = pd.crosstab(base_summer_2000_net[var1], base_summer_2000_net[var2])\n",
    "#        contingency_tables[(var1, var2)] = contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculez le V de Cramer pour chaque paire de variables\n",
    "#cramer_v_values = {}\n",
    "#for (var1, var2), contingency_table in contingency_tables.items():\n",
    "#    chi2, _, _, _ = chi2_contingency(contingency_table)\n",
    "#    n = contingency_table.sum().sum()\n",
    "#    min_dim = min(contingency_table.shape) - 1\n",
    "#    cramers_v = np.sqrt(chi2 / (n * min_dim))\n",
    "#    cramer_v_values[(var1, var2)] = cramers_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créez un DataFrame pour stocker les valeurs du V de Cramer\n",
    "#cramer_df = pd.DataFrame(index=categorical_vars, columns=categorical_vars)\n",
    "#for var1 in categorical_vars:\n",
    "#    for var2 in categorical_vars:\n",
    "#        cramer_df.loc[var1, var2] = cramer_v_values.get((var1, var2), cramer_v_values.get((var2, var1)))\n",
    "\n",
    "# Convertissez les valeurs en nombres décimaux\n",
    "#cramer_df = cramer_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une masque pour la moitié supérieure de la matrice, en excluant la diagonale inférieure\n",
    "#mask = np.triu(np.ones_like(cramer_df, dtype=bool), k=1)\n",
    "\n",
    "#plt.figure(figsize=(12, 8))\n",
    "#sns.heatmap(cramer_df, annot=True, cmap='BuGn', fmt=\".2f\", mask=mask)\n",
    "#plt.title(\"Matrice de corrélation - V de Cramer\")\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faire de nouveaux regroupement et suppression des variables utilisées pour la suite de l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ACM = base_summer_2000_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ACM = transform_base_ACM(base_summer_2000_net)\n",
    "\n",
    "# Affichage des colonnes après transformation\n",
    "print(base_ACM.columns)\n",
    "\n",
    "#base_ACM['Sport'].replace({\n",
    "#\n",
    "#'Judo'\t: 'Combat' ,\n",
    "#'Wrestling'\t: 'Combat' ,\n",
    "#'Taekwondo'\t: 'Combat' ,\n",
    "#'Fencing'\t: 'Combat' ,\n",
    "#'Boxing'\t: 'Combat' ,\n",
    "#'Badminton'\t:'Raquette',\n",
    "#'Tennis'\t:'Raquette',\n",
    "#'Table Tennis'\t:'Raquette',\n",
    "#'Swimming'\t: 'Natation',\n",
    "#'Synchronized Swimming'\t: 'Natation',\n",
    "#'Basketball'\t: 'Sport collectif',\n",
    "#'Handball'\t: 'Sport collectif',\n",
    "#'Football'\t: 'Sport collectif',\n",
    "#'Hockey'\t: 'Sport collectif',\n",
    "#'Water Polo'\t: 'Sport collectif',\n",
    "#'Softball'\t: 'Sport collectif',\n",
    "#'Volleyball'\t: 'Sport collectif',\n",
    "#'Baseball'\t: 'Sport collectif',\n",
    "#'Rugby Sevens'\t: 'Sport collectif',\n",
    "#'Beach Volleyball'\t: 'Sport collectif',\n",
    "#'Athletics'\t:'Athlétisme',\n",
    "#'Modern Pentathlon'\t:'Athlétisme',\n",
    "#'Triathlon'\t:'Athlétisme',\n",
    "#'Gymnastics'\t:'Gymnastique',\n",
    "#'Rhythmic Gymnastics'\t:'Gymnastique',\n",
    "#'Trampolining'\t:'Gymnastique',\n",
    "#'Sailing'\t:\"Sur l'eau\",\n",
    "#'Rowing'\t:\"Sur l'eau\",\n",
    "#'Diving'\t:\"Sur l'eau\",\n",
    "#'Canoeing'\t:\"Sur l'eau\",\n",
    "#'Weightlifting'\t:'Autres sports',\n",
    "#'Cycling'\t:'Autres sports',\n",
    "#'Equestrianism'\t:'Autres sports',\n",
    "#'Archery'\t:'Autres sports',\n",
    "#'Shooting'\t:'Autres sports',\n",
    "#'Golf'\t:'Autres sports'\n",
    "#}, inplace=True)\n",
    "\n",
    "#base_ACM['Sport'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_ACM['NOC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_ACM['NOC'].replace({\n",
    "#'CHN': 'Asie',\n",
    "#'FIN': 'Europe',\n",
    "#'ROU': 'Europe',\n",
    "#'NOR': 'Europe',\n",
    "#'NED': 'Europe',\n",
    "#'FRA': 'Europe',\n",
    "#'EST': 'Europe',\n",
    "#'ESP': 'Europe',\n",
    "#'EGY': 'Afrique',\n",
    "#'ITA': 'Europe',\n",
    "#'AZE': 'Asie',\n",
    "#'RUS': 'Europe',\n",
    "#'ARG': 'Amérique du Sud',\n",
    "#'CUB': 'Amérique du Nord',\n",
    "#'BLR': 'Europe',\n",
    "#'GRE': 'Europe',\n",
    "#'CMR': 'Afrique',\n",
    "#'MEX': 'Amérique du Nord',\n",
    "#'USA': 'Amérique du Nord',\n",
    "#'NCA': 'Amérique centrale',\n",
    "#'ALG': 'Afrique',\n",
    "#'BRN': 'Asie',\n",
    "#'IRQ': 'Asie',\n",
    "#'QAT': 'Asie',\n",
    "#'PAK': 'Asie',\n",
    "#'IRI': 'Asie',\n",
    "#'CAN': 'Amérique du Nord',\n",
    "#'IRL': 'Europe',\n",
    "#'AUS': 'Océanie',\n",
    "#'RSA': 'Afrique',\n",
    "#'MAR': 'Afrique',\n",
    "#'ERI': 'Afrique',\n",
    "#'SUD': 'Afrique',\n",
    "#'BEL': 'Europe',\n",
    "#'KAZ': 'Asie',\n",
    "#'BRU': 'Asie',\n",
    "#'KUW': 'Asie',\n",
    "#'MAS': 'Asie',\n",
    "#'INA': 'Asie',\n",
    "#'UZB': 'Asie',\n",
    "#'UAE': 'Asie',\n",
    "#'KGZ': 'Asie',\n",
    "#'TJK': 'Asie',\n",
    "#'JPN': 'Asie',\n",
    "#'GER': 'Europe',\n",
    "#'ETH': 'Afrique',\n",
    "#'TUR': 'Asie',\n",
    "#'SRI': 'Asie',\n",
    "#'ARM': 'Asie',\n",
    "#'CIV': 'Afrique',\n",
    "#'KEN': 'Afrique',\n",
    "#'NGR': 'Afrique',\n",
    "#'BRA': 'Amérique du Sud',\n",
    "#'SYR': 'Asie',\n",
    "#'CHI': 'Amérique du Sud',\n",
    "#'SUI': 'Europe',\n",
    "#'SWE': 'Europe',\n",
    "#'GUY': 'Amérique du Sud',\n",
    "#'GEO': 'Asie',\n",
    "#'POR': 'Europe',\n",
    "#'ANG': 'Afrique',\n",
    "#'COL': 'Amérique du Sud',\n",
    "#'DJI': 'Afrique',\n",
    "#'BAN': 'Asie',\n",
    "#'JOR': 'Asie',\n",
    "#'PLE': 'Asie',\n",
    "#'SOM': 'Afrique',\n",
    "#'KSA': 'Asie',\n",
    "#'VEN': 'Amérique du Sud',\n",
    "#'IND': 'Asie',\n",
    "#'GBR': 'Europe',\n",
    "#'GHA': 'Afrique',\n",
    "#'UGA': 'Afrique',\n",
    "#'TUN': 'Afrique',\n",
    "#'SLO': 'Europe',\n",
    "#'HON': 'Amérique centrale',\n",
    "#'TKM': 'Asie',\n",
    "#'MRI': 'Afrique',\n",
    "#'POL': 'Europe',\n",
    "#'NIG': 'Afrique',\n",
    "#'SKN': 'Amérique du Nord',\n",
    "#'NZL': 'Océanie',\n",
    "#'LBR': 'Afrique',\n",
    "#'SUR': 'Amérique du Sud',\n",
    "#'NEP': 'Asie',\n",
    "#'LBA': 'Afrique',\n",
    "#'MGL': 'Asie',\n",
    "#'PLW': 'Océanie',\n",
    "#'LTU': 'Europe',\n",
    "#'NAM': 'Afrique',\n",
    "#'UKR': 'Europe',\n",
    "#'ASA': 'Océanie',\n",
    "#'PUR': 'Amérique du Nord',\n",
    "#'SAM': 'Océanie',\n",
    "#'RWA': 'Afrique',\n",
    "#'CRO': 'Europe',\n",
    "#'DMA': 'Amérique du Nord',\n",
    "#'DEN': 'Europe',\n",
    "#'MLT': 'Europe',\n",
    "#'AUT': 'Europe',\n",
    "#'SEY': 'Afrique',\n",
    "#'DOM': 'Amérique du Nord',\n",
    "#'BIZ': 'Amérique centrale',\n",
    "#'PAR': 'Amérique du Sud',\n",
    "#'URU': 'Amérique du Sud',\n",
    "#'COM': 'Afrique',\n",
    "#'MDV': 'Asie',\n",
    "#'BEN': 'Afrique',\n",
    "#'TTO': 'Amérique du Nord',\n",
    "#'SGP': 'Asie',\n",
    "#'PER': 'Amérique du Sud',\n",
    "#'BER': 'Amérique du Nord',\n",
    "#'SCG': 'Europe',\n",
    "#'HUN': 'Europe',\n",
    "#'CYP': 'Europe',\n",
    "#'YEM': 'Asie',\n",
    "#'LIB': 'Afrique',\n",
    "#'OMA': 'Asie',\n",
    "#'IOA': 'Océanie',\n",
    "#'FIJ': 'Océanie',\n",
    "#'VAN': 'Océanie',\n",
    "#'JAM': 'Amérique du Nord',\n",
    "#'MDA': 'Europe',\n",
    "#'GUA': 'Amérique centrale',\n",
    "#'BUL': 'Europe',\n",
    "#'LAT': 'Europe',\n",
    "#'SRB': 'Europe',\n",
    "#'IVB': 'Amérique du Nord',\n",
    "#'VIN': 'Amérique centrale',\n",
    "#'ISL': 'Europe',\n",
    "#'CRC': 'Amérique centrale',\n",
    "#'ESA': 'Amérique centrale',\n",
    "#'CAF': 'Afrique',\n",
    "#'MAD': 'Afrique',\n",
    "#'CHA': 'Afrique',\n",
    "#'BIH': 'Europe',\n",
    "#'GUM': 'Océanie',\n",
    "#'PHI': 'Asie',\n",
    "#'CAY': 'Amérique du Nord',\n",
    "#'SVK': 'Europe',\n",
    "#'BAR': 'Amérique du Nord',\n",
    "#'ECU': 'Amérique du Sud',\n",
    "#'PAN': 'Amérique centrale',\n",
    "#'TLS': 'Asie',\n",
    "#'GAB': 'Afrique',\n",
    "#'BAH': 'Amérique du Nord',\n",
    "#'SMR': 'Europe',\n",
    "#'ISR': 'Asie',\n",
    "#'THA': 'Asie',\n",
    "#'BOT': 'Afrique',\n",
    "#'ROT': 'Océanie',\n",
    "#'KOR': 'Asie',\n",
    "#'PRK': 'Asie',\n",
    "#'MOZ': 'Afrique',\n",
    "#'CPV': 'Afrique',\n",
    "#'CZE': 'Europe',\n",
    "#'LAO': 'Asie',\n",
    "#'LUX': 'Europe',\n",
    "#'AND': 'Europe',\n",
    "#'ZIM': 'Afrique',\n",
    "#'GRN': 'Amérique du Nord',\n",
    "#'HKG': 'Asie',\n",
    "#'LCA': 'Amérique du Nord',\n",
    "#'HAI': 'Amérique du Nord',\n",
    "#'FSM': 'Océanie',\n",
    "#'MYA': 'Asie',\n",
    "#'AFG': 'Asie',\n",
    "#'SEN': 'Afrique',\n",
    "#'MTN': 'Afrique',\n",
    "#'COD': 'Afrique',\n",
    "#'GUI': 'Afrique',\n",
    "#'ANT': 'Amérique du Nord',\n",
    "#'CGO': 'Afrique',\n",
    "#'MKD': 'Europe',\n",
    "#'BOL': 'Amérique du Sud',\n",
    "#'TOG': 'Afrique',\n",
    "#'SLE': 'Afrique',\n",
    "#'MON': 'Europe',\n",
    "#'GEQ': 'Afrique',\n",
    "#'MNE': 'Europe',\n",
    "#'ISV': 'Amérique du Nord',\n",
    "#'PNG': 'Océanie',\n",
    "#'TAN': 'Afrique',\n",
    "#'COK': 'Océanie',\n",
    "#'ALB': 'Europe',\n",
    "#'MLI': 'Afrique',\n",
    "#'SWZ': 'Afrique',\n",
    "#'BDI': 'Afrique',\n",
    "#'ARU': 'Amérique du Sud',\n",
    "#'STP': 'Afrique',\n",
    "#'NRU': 'Océanie',\n",
    "#'GBS': 'Afrique',\n",
    "#'ZAM': 'Afrique',\n",
    "#'TPE': 'Asie',\n",
    "#'CAM': 'Amérique centrale',\n",
    "#'MAW': 'Afrique',\n",
    "#'BHU': 'Asie',\n",
    "#'VIE': 'Asie',\n",
    "#'GAM': 'Afrique',\n",
    "#'MHL': 'Océanie',\n",
    "#'AHO': 'Océanie',\n",
    "#'KIR': 'Océanie',\n",
    "#'TUV': 'Océanie',\n",
    "#'TGA': 'Océanie',\n",
    "#'LIE': 'Europe',\n",
    "#'KOS': 'Europe',\n",
    "#'SOL': 'Océanie',\n",
    "#'SSD': 'Afrique',\n",
    "#'LES': 'Afrique',\n",
    "#'BUR': 'Afrique',\n",
    "#}, inplace=True)\n",
    "\n",
    "#base_ACM['NOC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(base_ACM.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppresion des variables inutile pour la suite de l'analyse\n",
    "\n",
    "#base_ACM = base_ACM.drop(['ID', 'Name','Games', 'Year','City','Event'], axis=1)\n",
    "#print(base_ACM.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_acm(base_ACM)\n",
    "#remplacer les valeurs manquantes de la variable cibe par \"pas de médaille\"\n",
    "#base_ACM['Medal'].fillna('Pas_de_médaille', inplace=True)\n",
    "#print(base_ACM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fanalysis\n",
    "# utilisation du package fanalysis \n",
    "\n",
    "#acm = MCA()\n",
    "#acm.fit(base_ACM.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher les valeurs propres \n",
    "#acm.eig_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eigenvalues = acm.eig_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les valeurs propres associées à chaque composante principale\n",
    "#eigenvalues = acm.eig_\n",
    "\n",
    "# Calculer le pourcentage de chaque valeur propre\n",
    "#total_variance = sum(eigenvalues[0])\n",
    "#percentage_var = [(value / total_variance) * 100 for value in eigenvalues[0]]\n",
    "\n",
    "# Utiliser une palette de couleurs Seaborn et inverser l'ordre\n",
    "#sns.set(style=\"whitegrid\")\n",
    "#palette = sns.color_palette(\"BuGn\", len(percentage_var))\n",
    "#palette = palette[::-1]  # Inverser l'ordre des couleurs\n",
    "\n",
    "# Tracer le diagramme en barres des valeurs propres en pourcentage\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#bars = plt.bar(range(1, len(percentage_var) + 1), percentage_var, color=palette, edgecolor='black')\n",
    "#plt.xlabel('Composante Principale')\n",
    "#plt.ylabel('Pourcentage de Variance Expliquée')\n",
    "#plt.title('Diagramme en Barres des Valeurs Propres en Pourcentage - ACM')\n",
    "\n",
    "# Définir les ticks de l'axe x avec des valeurs entières\n",
    "#plt.xticks(range(1, len(percentage_var) + 1))\n",
    "\n",
    "# Ajouter les étiquettes de valeur uniquement pour les deux premières barres\n",
    "#for i, (bar, value) in enumerate(zip(bars, percentage_var)):\n",
    "#    if i < 2:\n",
    "#        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.2, f'{value:.2f}%',\n",
    "#                 ha='center', va='bottom', color='black', fontsize = 8)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indormation que procure l'ACM \n",
    "#info_col = acm.col_topandas()\n",
    "#info_col.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordonnée des modalité pour l'axe 1 et 2\n",
    "#coord_col = info_col[['col_coord_dim1', 'col_coord_dim2']]\n",
    "#print(coord_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contribution des modalités pour l'axe 1 et 2\n",
    "#contrib_col = pd.DataFrame(info_col[['col_contrib_dim1', 'col_contrib_dim2']])\n",
    "#contrib_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACM -projection des colonnes\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(7, 7))\n",
    "#ax.axis([-2.2, +2.2, -1.2, +1.5])\n",
    "#ax.plot([-2.2, +2.2], [0, 0], color=\"silver\", linestyle=\"--\")\n",
    "#ax.plot([0, 0], [-2.2, +2.2], color='silver', linestyle=\"--\")\n",
    "#ax.set_xlabel('Dim.1')\n",
    "#ax.set_ylabel('Dim.2')\n",
    "#plt.title(\"Modalité\")\n",
    "\n",
    "#for x, y, lbl in zip(coord_col.iloc[:, 0], coord_col.iloc[:, 1], coord_col.index):\n",
    "#    ax.text(x, y, lbl, horizontalalignment='center', verticalalignment='center', fontsize=7)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACM -projection en couleur\n",
    "#acm.mapping_col(num_x_axis = 1 , num_y_axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copie de la base pour les modèles \n",
    "base_model = base_ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model['Medal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroupement des 3 médailles en une modalité médaille\n",
    "base_model['Medal'].replace({\n",
    "    'Gold': 'medaille',\n",
    "    'Silver': 'medaille',\n",
    "    'Bronze': 'medaille',\n",
    "}, inplace=True)\n",
    "\n",
    "# Affichage des valeurs uniques après la modification\n",
    "base_model['Medal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y variable expliqué et X les variables explicatives \n",
    "y = base_model.Medal\n",
    "X = base_model.drop('Medal',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cette étape permet de ne pas créer des dummy pour réaliser les modèles \n",
    "\n",
    "cat_columns = ['Sex', 'NOC', 'Sport','Classe_age', 'Classe_height','Classe_weight']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat',OneHotEncoder(drop='first'), cat_columns)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG = LogisticRegression(random_state = 0, max_iter = 10000)\n",
    "LG.fit(X_train_encoded, y_train)\n",
    "print(\"Training score\", LG.score(X_train_encoded, y_train))\n",
    "print(\"Test score\", LG.score(X_test_encoded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur les données d'entraînement et de test\n",
    "y_train_pred = LG.predict(X_train_encoded)\n",
    "y_test_pred = LG.predict(X_test_encoded)\n",
    "\n",
    "# Matrice de confusion pour les données d'entraînement\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Matrice de confusion (Training Data):\")\n",
    "print(conf_matrix_train)\n",
    "\n",
    "# Matrice de confusion pour les données de test\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nMatrice de confusion (Test Data):\")\n",
    "print(conf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des indicateurs de performance du modèle : \n",
    "\n",
    "TP = conf_matrix_test[0, 0]\n",
    "FP = conf_matrix_test[1, 0]\n",
    "FN = conf_matrix_test[0, 1]\n",
    "TN = conf_matrix_test[1, 1]\n",
    "\n",
    "sensibilite = round((TP / (TP + FN)),2)*100\n",
    "specificite = round((TN / (TN + FP)),2)*100\n",
    "taux_erreur_alpha = round((FN / (TP + FN)),2)*100\n",
    "taux_erreur_beta = (FP / (FP + TN))*100\n",
    "taux_erreur_moyen = round(((FP + FN) / (FP + FN + TP + TN)),2)*100\n",
    "\n",
    "print(\"Sensibilité:\", sensibilite)\n",
    "print(\"Spécificité:\", specificite)\n",
    "print(\"Taux d'erreur alpha:\", taux_erreur_alpha)\n",
    "print(\"Taux d'erreur beta:\", taux_erreur_beta)\n",
    "print(\"Taux d'erreur moyen:\", taux_erreur_moyen) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une instance du modèle Random Forest\n",
    "RF = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement encodées\n",
    "RF.fit(X_train_encoded, y_train)\n",
    "\n",
    "print(\"Training score\", RF.score(X_train_encoded, y_train))\n",
    "print(\"Test score\", RF.score(X_test_encoded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur les données d'entraînement et de test\n",
    "y_train_pred_RF = RF.predict(X_train_encoded)\n",
    "y_test_pred_RF = RF.predict(X_test_encoded)\n",
    "\n",
    "# Matrice de confusion pour les données d'entraînement\n",
    "conf_matrix_train_RF = confusion_matrix(y_train, y_train_pred_RF)\n",
    "print(\"Matrice de confusion (Training Data):\")\n",
    "print(conf_matrix_train_RF)\n",
    "\n",
    "# Matrice de confusion pour les données de test\n",
    "conf_matrix_test_RF = confusion_matrix(y_test, y_test_pred_RF)\n",
    "print(\"\\nMatrice de confusion (Test Data):\")\n",
    "print(conf_matrix_test_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des indicateurs de performance du modèle : \n",
    "\n",
    "TP_RF = conf_matrix_test_RF[0, 0]\n",
    "FP_RF = conf_matrix_test_RF[1, 0]\n",
    "FN_RF = conf_matrix_test_RF[0, 1]\n",
    "TN_RF = conf_matrix_test_RF[1, 1]\n",
    "\n",
    "sensibilite_RF = round((TP_RF / (TP_RF + FN_RF)),2)*100\n",
    "specificite_RF = round((TN_RF / (TN_RF + FP_RF)),2)*100\n",
    "taux_erreur_alpha_RF = round((FN_RF / (TP_RF + FN_RF)),2)*100\n",
    "taux_erreur_beta_RF = (FP_RF / (FP_RF + TN_RF))*100\n",
    "taux_erreur_moyen_RF = round(((FP_RF + FN_RF) / (FP_RF + FN_RF + TP_RF + TN_RF)),2)*100\n",
    "\n",
    "print(\"Sensibilité:\", sensibilite_RF)\n",
    "print(\"Spécificité:\", specificite_RF)\n",
    "print(\"Taux d'erreur alpha:\", taux_erreur_alpha_RF)\n",
    "print(\"Taux d'erreur beta:\", taux_erreur_beta_RF)\n",
    "print(\"Taux d'erreur moyen:\", taux_erreur_moyen_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choix du k optimal\n",
    "error_rate = []\n",
    "k_values = list(filter(lambda x: x % 2 == 1, range(0, 50)))\n",
    "best_k = 0\n",
    "for i in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_encoded, y_train)\n",
    "    pred_i = knn.predict(X_test_encoded)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "print(error_rate.index(np.min(error_rate)))\n",
    "\n",
    "#figure qui montre le k otpimal\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(k_values,error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une instance du model knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 29)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement encodées\n",
    "knn.fit(X_train_encoded, y_train)\n",
    "\n",
    "print(\"Training score\", knn.score(X_train_encoded, y_train))\n",
    "print(\"Test score\", knn.score(X_test_encoded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur les données d'entraînement et de test\n",
    "y_train_pred_knn = knn.predict(X_train_encoded)\n",
    "y_test_pred_knn = knn.predict(X_test_encoded)\n",
    "\n",
    "# Matrice de confusion pour les données d'entraînement\n",
    "conf_matrix_train_knn = confusion_matrix(y_train, y_train_pred_knn)\n",
    "print(\"Matrice de confusion (Training Data):\")\n",
    "print(conf_matrix_train_knn)\n",
    "\n",
    "# Matrice de confusion pour les données de test\n",
    "conf_matrix_test_knn = confusion_matrix(y_test, y_test_pred_knn)\n",
    "print(\"\\nMatrice de confusion (Test Data):\")\n",
    "print(conf_matrix_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul des indicateurs de performance du modèle : \n",
    "\n",
    "TP_knn = conf_matrix_test_knn[0, 0]\n",
    "FP_knn = conf_matrix_test_knn[1, 0]\n",
    "FN_knn = conf_matrix_test_knn[0, 1]\n",
    "TN_knn = conf_matrix_test_knn[1, 1]\n",
    "\n",
    "sensibilite_knn = round((TP_knn / (TP_knn + FN_knn)),2)*100\n",
    "specificite_knn = round((TN_knn / (TN_knn + FP_knn)),2)*100\n",
    "taux_erreur_alpha_knn = round((FN_knn / (TP_RF + FN_knn)),2)*100\n",
    "taux_erreur_beta_knn = (FP_knn / (FP_knn + TN_knn))*100\n",
    "taux_erreur_moyen_knn = round(((FP_knn + FN_knn) / (FP_knn + FN_knn + TP_knn + TN_knn)),2)*100\n",
    "\n",
    "print(\"Sensibilité:\", sensibilite_knn)\n",
    "print(\"Spécificité:\", specificite_knn)\n",
    "print(\"Taux d'erreur alpha:\", taux_erreur_alpha_knn)\n",
    "print(\"Taux d'erreur beta:\", taux_erreur_beta_knn)\n",
    "print(\"Taux d'erreur moyen:\", taux_erreur_moyen_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interprétation du modèle Regression logisitique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permet d'obtenir les coefficients directeurs associé aux modalités\n",
    "\n",
    "coefficients = LG.coef_\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les noms des colonnes après la transformation\n",
    "column_names = preprocessor.named_transformers_['cat'].get_feature_names_out(cat_columns)\n",
    "\n",
    "# Associer les coefficients aux noms des colonnes\n",
    "coefficients_dict = dict(zip(column_names, LG.coef_[0]))\n",
    "\n",
    "# Afficher les coefficients avec les noms des colonnes associés\n",
    "for variable, coef in coefficients_dict.items():\n",
    "    print(f\"{variable}: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permet d'obtenir le coefficient de l'individu de référence\n",
    "\n",
    "intercept = LG.intercept_\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenez les probabilités prédites\n",
    "predicted_probabilities = LG.predict_proba(X_train_encoded)\n",
    "\n",
    "# Calculez les z-scores des coefficients\n",
    "z_scores = np.zeros(shape=(len(LG.coef_[0]),))\n",
    "for index, coef in enumerate(LG.coef_[0]):\n",
    "    z_scores[index] = coef / np.std(predicted_probabilities[:, 1])\n",
    "\n",
    "# Convertissez les z-scores en p-values approximatives\n",
    "p_values = scipy.stats.norm.sf(abs(z_scores))\n",
    "p_values\n",
    "\n",
    "# Créez un dictionnaire pour associer les noms de colonnes après la transformation aux p-values\n",
    "p_values_dict = dict(zip(column_names, p_values))\n",
    "\n",
    "# Affichez les associations entre les modalités et les p-values\n",
    "for column_name, p_value in p_values_dict.items():\n",
    "    if p_value < 0.001:\n",
    "        print(f\"{column_name}: <0.001\")\n",
    "    else:\n",
    "        print(f\"{column_name}: {p_value:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
